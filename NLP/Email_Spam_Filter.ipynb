{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Email Spam Filter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fyn-bhBDKO4P",
        "colab_type": "text"
      },
      "source": [
        "# Download Data and Pretrained Word Embeddings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUANY4XtO21u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data/spam_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaqpMpuHO2vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Get dataset and save in local folder ##\n",
        "\n",
        "!wget https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham.tar.bz2\n",
        "!wget https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2\n",
        "!wget https://spamassassin.apache.org/old/publiccorpus/20030228_spam.tar.bz2\n",
        "!wget https://spamassassin.apache.org/old/publiccorpus/20050311_spam_2.tar.bz2\n",
        "!wget https://spamassassin.apache.org/old/publiccorpus/20030228_hard_ham.tar.bz2\n",
        "\n",
        "!tar xvjf 20030228_easy_ham_2.tar.bz2\n",
        "!tar xvjf 20030228_easy_ham.tar.bz2\n",
        "!tar xvjf 20030228_hard_ham.tar.bz2    \n",
        "!tar xvjf 20030228_spam.tar.bz2\n",
        "!tar xvjf 20050311_spam_2.tar.bz2\n",
        "\n",
        "!mv easy_ham data/spam_data  \n",
        "!mv easy_ham_2 data/spam_data\n",
        "!mv hard_ham data/spam_data\n",
        "!mv spam data/spam_data\n",
        "!mv spam_2 data/spam_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqXqV3uNKTAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Download and unzip the GloVe embedding ##\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "!python -m gensim.scripts.glove2word2vec -i glove.6B.300d.txt -o glove.6B.300d.word2vec.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yb3qNBUPesx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import NLTK packages ##\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRP9_1TKJgz8",
        "colab_type": "text"
      },
      "source": [
        "# Start Coding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2lesDxPJgz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import email"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu1PzBStJg0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'data/spam_data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IHD0C6MJg0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "easy_ham_paths = glob.glob(path+'easy_ham/*')\n",
        "easy_ham_2_paths = glob.glob(path+'easy_ham_2/*')\n",
        "hard_ham_paths = glob.glob(path+'hard_ham/*')\n",
        "spam_paths = glob.glob(path+'spam/*')\n",
        "spam_2_paths = glob.glob(path+'spam_2/*')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4RbluYtJg0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_email_content(email_path):\n",
        "    file = open(email_path,encoding='latin1')\n",
        "    try:\n",
        "        msg = email.message_from_file(file)\n",
        "        for part in msg.walk():\n",
        "            if part.get_content_type() == 'text/plain':\n",
        "                return part.get_payload() # prints the raw text\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        \n",
        "        \n",
        "def get_email_content_bulk(email_paths):\n",
        "    email_contents = [get_email_content(o) for o in email_paths]\n",
        "    return email_contents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTFlyxYkJg0S",
        "colab_type": "text"
      },
      "source": [
        "# Split data into train/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKJ-Hz6VJg0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGCmvDs7Jg0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ham_path = [\n",
        "    easy_ham_paths,\n",
        "    easy_ham_2_paths,\n",
        "    hard_ham_paths\n",
        "]\n",
        "\n",
        "spam_path = [\n",
        "    spam_paths,\n",
        "    spam_2_paths\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJt4krb0Jg0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ham_sample = np.array([train_test_split(o) for o in ham_path])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe7ksHt6Jg0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ham_train = np.array([])\n",
        "ham_test = np.array([])\n",
        "for o in ham_sample:\n",
        "    ham_train = np.concatenate((ham_train,o[0]),axis=0)\n",
        "    ham_test = np.concatenate((ham_test,o[1]),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbfDL-IJJg0o",
        "colab_type": "code",
        "outputId": "c43b1eb0-65e6-4821-a9f7-13798a9a7b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ham_train.shape, ham_test.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3113,), (1040,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJXnebpdJg0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spam_sample = np.array([train_test_split(o) for o in spam_path])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c7DqHJvJg0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spam_train = np.array([])\n",
        "spam_test = np.array([])\n",
        "for o in spam_sample:\n",
        "    spam_train = np.concatenate((spam_train,o[0]),axis=0)\n",
        "    spam_test = np.concatenate((spam_test,o[1]),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-SAPJxHJg01",
        "colab_type": "code",
        "outputId": "ed2093b9-c514-4908-9b3c-dd6ac7c9c693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spam_train.shape, spam_test.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1422,), (476,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5-FPweOJg06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ham_train_label = [0]*ham_train.shape[0]\n",
        "spam_train_label = [1]*spam_train.shape[0]\n",
        "x_train = np.concatenate((ham_train,spam_train))\n",
        "y_train = np.concatenate((ham_train_label,spam_train_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkVocQJTJg0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ham_test_label = [0]*ham_test.shape[0]\n",
        "spam_test_label = [1]*spam_test.shape[0]\n",
        "x_test = np.concatenate((ham_test,spam_test))\n",
        "y_test = np.concatenate((ham_test_label,spam_test_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCWVWIByJg1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_shuffle_index = np.random.permutation(np.arange(0,x_train.shape[0]))\n",
        "test_shuffle_index = np.random.permutation(np.arange(0,x_test.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2sjP41_Jg1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train[train_shuffle_index]\n",
        "y_train = y_train[train_shuffle_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwAqxlTRJg1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = x_test[test_shuffle_index]\n",
        "y_test = y_test[test_shuffle_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyuS6Vl0Jg1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = get_email_content_bulk(x_train)\n",
        "x_test = get_email_content_bulk(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5ICGxkSJg1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_null(datas,labels):\n",
        "    not_null_idx = [i for i,o in enumerate(datas) if o is not None]\n",
        "    return np.array(datas)[not_null_idx],np.array(labels)[not_null_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPIhk_zkJg1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train = remove_null(x_train,y_train)\n",
        "x_test,y_test = remove_null(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKqYziutJg1d",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVgntkNJg1e",
        "colab_type": "text"
      },
      "source": [
        "## Process sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryMjuCo0Jg1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMg4m6JiJg1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_hyperlink(word):\n",
        "    return  re.sub(r\"http\\S+\", \"\", word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEF6lZ3xJg1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_lower(word):\n",
        "    result = word.lower()\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3mOLxp0Jg1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_number(word):\n",
        "    result = re.sub(r'\\d+', '', word)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5axXMo-Jg1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(word):\n",
        "    result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EWMmVfFJg1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_whitespace(word):\n",
        "    result = word.strip()\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiiWG07CJg1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_newline(word):\n",
        "    return word.replace('\\n','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HB8JP9NJg12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_up_pipeline(sentence):\n",
        "    cleaning_utils = [remove_hyperlink,\n",
        "                      replace_newline,\n",
        "                      to_lower,\n",
        "                      remove_number,\n",
        "                      remove_punctuation,remove_whitespace]\n",
        "    for o in cleaning_utils:\n",
        "        sentence = o(sentence)\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S0QuLxnJg14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = [clean_up_pipeline(o) for o in x_train]\n",
        "x_test = [clean_up_pipeline(o) for o in x_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MHRNilvJg16",
        "colab_type": "text"
      },
      "source": [
        "## Process word by word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTj_mB9hJg17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6614b74c-73fb-487b-deed-abcd0cf52d80"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqRqAdCIJg19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1BxhgJvJg1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = [word_tokenize(o) for o in x_train]\n",
        "x_test = [word_tokenize(o) for o in x_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWmozlZbJg2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_words(words):\n",
        "    result = [i for i in words if i not in ENGLISH_STOP_WORDS]\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV2Md7NhJg2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_stemmer(words):\n",
        "    return [stemmer.stem(o) for o in words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ5TwLdVJg2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_lemmatizer(words):\n",
        "    return [lemmatizer.lemmatize(o) for o in words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DANT21luJg2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_token_pipeline(words):\n",
        "    cleaning_utils = [remove_stop_words,word_stemmer,word_lemmatizer]\n",
        "    for o in cleaning_utils:\n",
        "        words = o(words)\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YTl8p_oJg2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = [clean_token_pipeline(o) for o in x_train]\n",
        "x_test = [clean_token_pipeline(o) for o in x_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZkuozesJg2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a4d8c815-915b-44d8-9e4d-52d23016b59f"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "w2v = KeyedVectors.load_word2vec_format('glove.6B.300d.word2vec.txt',binary=False)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cIzc5Laoma7",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb4fGxa-ossO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function is needed to include in the cell to show the plotly graph \n",
        "# in colab\n",
        "\n",
        "def configure_plotly_browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdsqVHibo7r3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3cc0c56b-7124-4043-b16c-c9db50e177c0"
      },
      "source": [
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "from plotly import tools\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erACrIsBOkyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_join = [\" \".join(o) for o in x_train]\n",
        "x_test_join = [\" \".join(o) for o in x_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlTQYuciNt3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spam_train_index = [i for i,o in enumerate(y_train) if o == 1]\n",
        "non_spam_train_index = [i for i,o in enumerate(y_train) if o == 0]\n",
        "\n",
        "spam_email = np.array(x_train_join)[spam_train_index]\n",
        "non_spam_email = np.array(x_train_join)[non_spam_train_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbB0hwTWApoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## N-gram bar chart visualization ##\n",
        "\n",
        "## custom function for ngram generation ##\n",
        "def generate_ngrams(text, n_gram=1):\n",
        "    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n",
        "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
        "    return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "## custom function for horizontal bar chart ##\n",
        "def horizontal_bar_chart(df, color):\n",
        "    trace = go.Bar(\n",
        "        y=df[\"word\"].values[::-1],\n",
        "        x=df[\"wordcount\"].values[::-1],\n",
        "        showlegend=False,\n",
        "        orientation = 'h',\n",
        "        marker=dict(\n",
        "            color=color,\n",
        "        ),\n",
        "    )\n",
        "    return trace\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgnRQGssBABx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_in_bar_chart(word_count=1):\n",
        "    ## Get the bar chart from non-spam email ##\n",
        "    freq_dict = defaultdict(int)\n",
        "    for sent in non_spam_email:\n",
        "        for word in generate_ngrams(sent,word_count):\n",
        "            freq_dict[word] += 1\n",
        "    fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
        "    fd_sorted.columns = [\"word\", \"wordcount\"]\n",
        "    trace0 = horizontal_bar_chart(fd_sorted.head(20), 'orange')\n",
        "\n",
        "    ## Get the bar chart from spam email ##\n",
        "    freq_dict = defaultdict(int)\n",
        "    for sent in spam_email:\n",
        "        for word in generate_ngrams(sent,word_count):\n",
        "            freq_dict[word] += 1\n",
        "    fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
        "    fd_sorted.columns = [\"word\", \"wordcount\"]\n",
        "    trace1 = horizontal_bar_chart(fd_sorted.head(20), 'orange')\n",
        "\n",
        "    # Creating two subplots\n",
        "    fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,\n",
        "                              subplot_titles=[\"Frequent words of non spam email\", \n",
        "                                              \"Frequent words of spam email\"])\n",
        "    fig.append_trace(trace0, 1, 1)\n",
        "    fig.append_trace(trace1, 1, 2)\n",
        "    fig['layout'].update(height=600, width=800, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\n",
        "    py.iplot(fig, filename='word-plots')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfwEZilhBEbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "visualize_in_bar_chart(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-bC1GKvqQlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Wordcloud Visualization ##\n",
        "\n",
        "def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n",
        "                   title = None, title_size=40, image_color=False):\n",
        "    stopwords = set(STOPWORDS)\n",
        "    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n",
        "    stopwords = stopwords.union(more_stopwords)\n",
        "\n",
        "    wordcloud = WordCloud(background_color='black',\n",
        "                    stopwords = stopwords,\n",
        "                    max_words = max_words,\n",
        "                    max_font_size = max_font_size, \n",
        "                    random_state = 42,\n",
        "                    width=800, \n",
        "                    height=400,\n",
        "                    mask = mask)\n",
        "    wordcloud.generate(str(text))\n",
        "    \n",
        "    plt.figure(figsize=figure_size)\n",
        "    if image_color:\n",
        "        image_colors = ImageColorGenerator(mask);\n",
        "        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n",
        "        plt.title(title, fontdict={'size': title_size,  \n",
        "                                  'verticalalignment': 'bottom'})\n",
        "    else:\n",
        "        plt.imshow(wordcloud);\n",
        "        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n",
        "                                  'verticalalignment': 'bottom'})\n",
        "    plt.axis('off');\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "#plot_wordcloud(spam_email,title = 'Spam Email')\n",
        "#plot_wordcloud(non_spam_email,title=\"Non Spam Email\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNlLm11DRVuG",
        "colab_type": "text"
      },
      "source": [
        "# TF-IDF based Embedding With  Naive-Bayes and SVM Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-cdLjfORq-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Compute TF-IDF features using sklearn ##\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "vectorizer.fit_transform(x_train_join)\n",
        "x_train_features = vectorizer.transform(x_train_join)\n",
        "x_test_features = vectorizer.transform(x_test_join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50z3mJ5FWBD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f749a686-b7fe-4ddb-d920-bdf3bb0d28df"
      },
      "source": [
        "## Train a Naive Bayes Classifier ##\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = GaussianNB()\n",
        "\n",
        "clf.fit(x_train_features.toarray(),y_train)\n",
        "\n",
        "clf.score(x_test_features.toarray(),y_test)\n",
        "\n",
        "clf.score(x_train_features.toarray(),y_train)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9963302752293578"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAwA2Jn3OLTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "901a0ded-9ca5-481c-a5db-f6fb53ee5088"
      },
      "source": [
        "## Train an SVM based Classifier ##\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "\n",
        "clf = SVC(gamma='auto')\n",
        "\n",
        "clf.fit(x_train_features.toarray(),y_train)\n",
        "\n",
        "clf.score(x_test_features.toarray(),y_test)\n",
        "\n",
        "clf.score(x_train_features.toarray(),y_train)\n",
        "\n",
        "clf_disp = plot_roc_curve(clf, x_test_features.toarray(),y_test)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxfQbab_Jg2c",
        "colab_type": "text"
      },
      "source": [
        "# GloVe-based Embeding and Training using Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsHRosFGJg2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBwaw0D6Jg2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 2000\n",
        "max_features = 50000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v4x8c3GJg2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = 'glove.6B.300d.txt'\n",
        "tokenizer = Tokenizer(num_words=max_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOlphmFrJg2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFgjFkSRJg2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_features = np.array(tokenizer.texts_to_sequences(x_train))\n",
        "x_test_features = np.array(tokenizer.texts_to_sequences(x_test))\n",
        "\n",
        "x_train_features = pad_sequences(x_train_features,maxlen=maxlen)\n",
        "x_test_features = pad_sequences(x_test_features,maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crmVKUQNJg2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr): \n",
        "  return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9ZXFPTgJg2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "        \n",
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(LSTM(64, activation='tanh',return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZYY8gJmJg20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.layers[1].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hon62hmIJg21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train_features,y_train, batch_size=512, epochs=20, \n",
        "          validation_data=(x_test_features, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkSl2rJxJg23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOoYojWtJg3O",
        "colab_type": "text"
      },
      "source": [
        "# Custom Embedding and training using Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zncorqyvJg3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9W9PJZDJg3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## some config values \n",
        "embed_size = 100 # how big is each word vector\n",
        "max_feature = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "max_len = 2000 # max number of words in a question to use"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfrdY0NbJg3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ulmgu2_Jg3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15_Olth-Jg3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_features = np.array(tokenizer.texts_to_sequences(x_train))\n",
        "x_test_features = np.array(tokenizer.texts_to_sequences(x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STmnfjEsJg3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_features = pad_sequences(x_train_features,maxlen=max_len)\n",
        "x_test_features = pad_sequences(x_test_features,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxXSia3XJg3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 100\n",
        "\n",
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(max_feature, embed_size)(inp)\n",
        "x = Bidirectional(LSTM(64, activation = 'tanh', return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLR9OTUGJg3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train_features, y_train, batch_size=512, epochs=20, validation_data=(x_test_features, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6ddZ8E1Jg3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5yDxKs7Jg3l",
        "colab_type": "text"
      },
      "source": [
        "## Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzGF_hA4Jg3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,f1_score, precision_score,recall_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkJQ-yURJg3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict  = [1 if o>0.5 else 0 for o in model.predict(x_test_features)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB21196PJg3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix(y_test,y_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kberNYWIJg3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test,y_predict).ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kshhXwFAJg3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_predict)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_predict)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8pacWZkJg3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_score(y_test,y_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJyDyVJHJg3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test,y_predict)\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78278baOJg3z",
        "colab_type": "text"
      },
      "source": [
        "# Plot normalized confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSafPEb4Jg3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Non Spam','Spam'], normalize=False,\n",
        "                      title='Confusion matrix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRASX4txVNJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}